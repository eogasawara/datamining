```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Classificação

## Visão Geral
A classificação é uma tarefa de aprendizado supervisionado que aprende a mapear vetores de atributos para rótulos de classe. Ela envolve duas etapas: construção do modelo a partir de dados rotulados e aplicação do modelo a novos casos.  
Slides: 1–6.

## Como ler este roteiro
Use este roteiro como comparação incremental de modelos:
1. estabeleça baseline (Regra Zero);
2. avance para modelos mais expressivos;
3. compare sempre matriz de confusão e métricas no conjunto de teste.
Assim, o ganho de desempenho fica conectado ao custo de complexidade.

## Configuração

```{r}
# Slides 1–3: contexto e definição
library(daltoolbox)

# Slides 9: conjunto de dados de exemplo
iris <- datasets::iris
head(iris)
table(iris$Species)

# Preparacao treino/teste (usado nos exemplos)
set.seed(1)
split_random <- sample_random()
split_random <- train_test(split_random, iris)
iris_train <- split_random$train
iris_test <- split_random$test

slevels <- levels(iris$Species)

# Distribuicao das classes
class_tbl <- rbind(
  table(iris[, "Species"]),
  table(iris_train[, "Species"]),
  table(iris_test[, "Species"])
)
rownames(class_tbl) <- c("dataset", "training", "test")
class_tbl

# Helper: avaliacao padrao DALToolbox
# Slides 21–25: avaliacao

eval_model <- function(model, train, test, target_col) {
  evaluate_safe <- function(data, prediction, target_col) {
    predictand <- adjust_class_label(data[, target_col])
    eval <- evaluate(model, predictand, prediction)

    if (is.null(eval) || is.null(eval$metrics)) {
      proxy <- classification(target_col, colnames(predictand))

      if (is.factor(prediction) || is.character(prediction) || is.vector(prediction)) {
        pred <- factor(as.vector(prediction), levels = colnames(predictand))
        prediction <- adjust_class_label(pred)
      } else {
        prediction <- as.matrix(prediction)
        if (is.null(colnames(prediction))) {
          colnames(prediction) <- colnames(predictand)[seq_len(ncol(prediction))]
        }
        aligned <- matrix(0, nrow(prediction), ncol(predictand))
        colnames(aligned) <- colnames(predictand)
        common <- intersect(colnames(prediction), colnames(predictand))
        aligned[, common] <- prediction[, common, drop = FALSE]
        prediction <- aligned
      }

      eval <- evaluate(proxy, predictand, prediction)
    }

    list(eval = eval, predictand = predictand)
  }

  train_prediction <- predict(model, train)
  train_res <- evaluate_safe(train, train_prediction, target_col)
  print(train_res$eval$metrics)

  test_prediction <- predict(model, test)
  test_res <- evaluate_safe(test, test_prediction, target_col)
  print(test_res$eval$metrics)

  list(
    train_prediction = train_prediction,
    train_predictand = train_res$predictand,
    test_prediction = test_prediction,
    test_predictand = test_res$predictand
  )
}

pred_to_label <- function(pred) {
  if (is.data.frame(pred) || is.matrix(pred)) {
    if (ncol(pred) == 1) {
      return(as.vector(pred[, 1]))
    }
    cols <- colnames(pred)
    if (is.null(cols)) cols <- seq_len(ncol(pred))
    return(apply(pred, 1, function(r) cols[which.max(r)]))
  }
  if (is.list(pred)) {
    return(unlist(pred))
  }
  as.vector(pred)
}
```

## Regra Zero (Baseline)
A Regra Zero define uma referência mínima de desempenho, sempre prevendo a classe majoritária. Qualquer modelo útil deve superar esse baseline.  
Slides: 10.

```{r}
# Slides 10: Regra Zero (baseline)
model_majority <- cla_majority("Species", slevels)
model_majority <- fit(model_majority, iris_train)
res_majority <- eval_model(model_majority, iris_train, iris_test, "Species")
```

## Árvores de Decisão
Árvores de decisão particionam o espaço de atributos recursivamente usando critérios como ganho de informação, produzindo modelos interpretáveis.  
Slides: 11–20.

```{r}
# Slides 11–20: Arvore de Decisao
model_dtree <- cla_dtree("Species", slevels)
model_dtree <- fit(model_dtree, iris_train)
res_dtree <- eval_model(model_dtree, iris_train, iris_test, "Species")
```

### Matriz de Confusão
A matriz de confusão permite analisar erros específicos de classificação e derivar métricas como precisão e revocação.  
Slides: 23–25.

```{r}
# Slides 21–25: avaliacao e matriz de confusao (exemplo com arvore)
# predict() pode retornar data.frame; usar vetor para a tabela
conf_dtree <- table(
  Pred = pred_to_label(res_dtree$test_prediction),
  Actual = pred_to_label(res_dtree$test_predictand)
)
conf_dtree
```

## Classificação Bayesiana
Naive Bayes assume independência condicional entre atributos. Apesar da suposição forte, tende a ser eficiente e competitivo em diversos cenários.  
Slides: 33–40.

```{r}
# Slides 33–40: Naive Bayes
model_nb <- cla_nb("Species", slevels)
model_nb <- fit(model_nb, iris_train)
res_nb <- eval_model(model_nb, iris_train, iris_test, "Species")
```

## Regressão Logística
Modela a probabilidade de pertencimento a uma classe via função logística. Aqui, reduzimos para um problema binário (versicolor vs. não-versicolor), comparando modelo completo e simplificado.  
Slides: 41–47.

```{r}
# Slides 41–47: Regressao Logistica (versicolor vs nao-versicolor)
# Problema binario
fg_bin <- feature_generation(
  IsVersicolor = ifelse(Species == "versicolor", "versicolor", "not_versicolor")
)
iris_bin_train <- transform(fg_bin, iris_train)
iris_bin_test <- transform(fg_bin, iris_test)
iris_bin_train$IsVersicolor <- factor(iris_bin_train$IsVersicolor)
iris_bin_test$IsVersicolor <- factor(iris_bin_test$IsVersicolor)

# Modelo completo
model_glm_full <- cla_glm(
  attribute = "IsVersicolor",
  positive = "versicolor",
  features = c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")
)
model_glm_full <- fit(model_glm_full, iris_bin_train)
res_glm_full <- eval_model(model_glm_full, iris_bin_train, iris_bin_test, "IsVersicolor")
conf_full <- table(
  Pred = pred_to_label(res_glm_full$test_prediction),
  Actual = pred_to_label(res_glm_full$test_predictand)
)
conf_full

# Modelo simplificado (petal length/width)
model_glm_simple <- cla_glm(
  attribute = "IsVersicolor",
  positive = "versicolor",
  features = c("Petal.Length", "Petal.Width")
)
model_glm_simple <- fit(model_glm_simple, iris_bin_train)
res_glm_simple <- eval_model(model_glm_simple, iris_bin_train, iris_bin_test, "IsVersicolor")
conf_simple <- table(
  Pred = pred_to_label(res_glm_simple$test_prediction),
  Actual = pred_to_label(res_glm_simple$test_predictand)
)
conf_simple
```

## k-NN (Aprendizagem Preguiçosa)
Métodos baseados em instâncias adiam o processamento para a fase de predição. O k-NN decide pela maioria dos k vizinhos mais próximos.  
Slides: 48–53.

```{r}
# Slides 48–53: Aprendizagem preguiçosa (k-NN)
model_knn <- cla_knn("Species", slevels, k = 1)
model_knn <- fit(model_knn, iris_train)
res_knn <- eval_model(model_knn, iris_train, iris_test, "Species")
```

## Próxima Aula
Métodos avançados (SVM, ensembles, boosting, tuning e seleção de atributos) foram concentrados em `08-Classification-Advanced.Rmd` para evitar repetição e manter a progressão didática.

## Referências
- Han, J., Pei, J., & Tong, H. (2022). *Data Mining: Concepts and Techniques* (4th ed.). Morgan Kaufmann.
- Mitchell, T. (1997). *Machine Learning*. McGraw-Hill.
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Cortes, C., & Vapnik, V. (1995). Support-Vector Networks. *Machine Learning*, 20(3), 273–297.
- Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5–32.
- Cover, T., & Hart, P. (1967). Nearest neighbor pattern classification. *IEEE Trans. Information Theory*, 13(1), 21–27.
- Hosmer, D., Lemeshow, S., & Sturdivant, R. (2013). *Applied Logistic Regression* (3rd ed.). Wiley.


